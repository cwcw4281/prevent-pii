{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb8a33-e3b3-4f60-ba65-a3e2f8d27559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from faker import Faker\n",
    "import random\n",
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "from transformers import pipeline, Pipeline\n",
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error() \n",
    "\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "CONS model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "fake = Faker()\n",
    "supported_masks = {\n",
    "    'DOB': [\"date of birth\", lambda : fake.date(end_datetime = date(2010, 1, 1)) ],\n",
    "    'BUILDING': [\"a building name\", lambda : fake.company() ] ,\n",
    "    'DATE': [\"a date\", lambda : fake.date() ],\n",
    "    'DRIVERLICENSE': [\"a driver license number\", lambda : fake.passport_number() ],\n",
    "    'EMAIL': [\"an email address\", lambda : fake.simple_profile()['mail'] ],\n",
    "    'GEOCOORD': [\"a geographic coordinate\", lambda : \"(\"+str(fake.latlng()[0])+\", \"+str(fake.latlng()[1])+\")\" ],\n",
    "    'GIVENNAME': [\"a full name\", lambda : fake.name_nonbinary() ],\n",
    "    'FIRSTNAME': [\"a first name\", lambda : fake.first_name() ],\n",
    "    'IDCARD': [\"a passport ID number\", lambda : fake.passport_number() ],\n",
    "    'IPV4': [\"an IP address\", lambda : \".\".join(str(random.randint(0, 255)) for _ in range(4))],\n",
    "    'LASTNAME': [\"a last name\", lambda : fake.last_name() ],\n",
    "    'PASSPORT': [\"a passport related information\", lambda : fake.passport_number() ],\n",
    "    'SEX': [\"gender information\", lambda : [\"female\", \"male\", \"non-binary\"][random.randint(0,2)]],\n",
    "    'SOCIALNUMBER': [\"a 10-digit social security number\", lambda : fake.ssn()],\n",
    "    'TEL': [\"a telephone number\", lambda: fake.phone_number() ],\n",
    "    'PHONENUMBER': [\"a telephone number\", lambda: fake.phone_number() ],\n",
    "    'USERNAME': [\"a username\", lambda : fake.simple_profile()['username']],\n",
    "    'TIME': ['a time of the day', lambda : str(random.randint(0, 24))+\":\"+str(random.randint(0, 60)) ],\n",
    "    'AGE': ['an age number', lambda : str(random.randint(10, 80)) ],\n",
    "    'CITY': ['a city name', lambda : fake.city() ],\n",
    "    \"MIDDLENAME\": ['a middle name', lambda : fake.first_name()],\n",
    "    \"PREFIX\": ['a name prefix', lambda : fake.prefix() ]\n",
    "}\n",
    "anonymizer_model = load_model(\"taro-pudding/privacy-200k-masking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b1106dd-fee8-4076-b364-a33402699cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_tag: str, use_gpu: bool = False) -> Optional[Pipeline]:\n",
    "    device = 0 if use_gpu else -1\n",
    "    try:\n",
    "        model = pipeline(\"token-classification\", model=model_tag, tokenizer=model_tag, device=device)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Model: \\n\\n{e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_entity_map(model_output: List[dict], text: str) -> dict:\n",
    "    entity_map = {}\n",
    "    for token in model_output:\n",
    "        start = token[\"start\"]\n",
    "        end = token[\"end\"]\n",
    "        entity = text[start: end]\n",
    "        entity_map[entity] = token[\"entity_group\"]\n",
    "    return entity_map\n",
    "\n",
    "\n",
    "def replace_entities(text: str, entity_map: dict) -> str:\n",
    "    for word in entity_map:\n",
    "        if word in text:\n",
    "            text = text.replace(word, f\"[{entity_map[word]}]\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def mask_pii(input_sentence: str, anonymizer: Pipeline) -> Optional[str]:\n",
    "    output = anonymizer(input_sentence, aggregation_strategy=\"simple\")\n",
    "    if isinstance(output, list):\n",
    "        entity_map = create_entity_map(output, input_sentence)\n",
    "        return replace_entities(input_sentence, entity_map)\n",
    "    else:\n",
    "        print(\"Output is not in the expected format\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_layer1_text(sentence):\n",
    "    masked_text = mask_pii(sentence, anonymizer_model)\n",
    "    return masked_text\n",
    "\n",
    "def generate_layer2_text(layer1_text):\n",
    "    layer2_text = layer1_text\n",
    "    for mask in supported_masks.keys():\n",
    "        layer2_text = layer2_text.replace(\"[\"+mask+\"]\", supported_masks[mask][1]())\n",
    "    return layer2_text\n",
    "\n",
    "def generate_layer3_text(layer2_text):    \n",
    "    def get_response(input_text,num_return_sequences,num_beams):\n",
    "      batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "      translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "      tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "      return tgt_text\n",
    "\n",
    "    return get_response(layer2_text, 1, 10)\n",
    "\n",
    "def main(sentence):\n",
    "    layer1_text = generate_layer1_text(sentence)\n",
    "    sample = [[sentence, layer1_text, \"\", \"\"]]\n",
    "    df = pd.DataFrame(sample, columns=['original_text', 'layer1_text', 'layer2_text', 'layer3_text'])\n",
    "    df['layer2_text'] = df.apply(lambda row: generate_layer2_text(row['layer1_text']), axis=1)\n",
    "    df['layer3_text'] = df.apply(lambda row: generate_layer3_text(row['layer2_text']), axis=1)\n",
    "    print(df['layer3_text'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5de3196-86e4-48ce-bff1-fac9fe99dd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emily Wastson sings her social security number out loud at 11 MetroTech Center in Owenview, NY.']\n"
     ]
    }
   ],
   "source": [
    "main(\"Emily Wastson lives in 6 MetroTech Center, Brooklyn, NY 11201 and sings her social security number 100-100-2222 out loud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff3db1b-2835-4625-bdda-e0829f665f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
